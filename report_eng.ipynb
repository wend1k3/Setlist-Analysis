{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data-Driven Setlist Analysis with Spotify Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Project Goals\n",
    "Analyze the track selection from three Hacken Lee's concerts that share the same theme. \n",
    "\n",
    "\n",
    "\n",
    "Specifically, this project explores:\n",
    "- *How are hit songs and lesser-known sidetracks balanced across the setlists?*\n",
    "- *Which albums are most favoured?*\n",
    "- *How do the setlists vary across different concert locations?*\n",
    "\n",
    "### 1.2 Why Hacken Lee?\n",
    "First of all, I like him. \n",
    "\n",
    "Secondly, Hacken Lee is a prominent Cantopop singer known for his rich discography: he is one of the few singers whose career spans from the 1980s to the 2020s, maintaining both popularity and a steady output of albums. He is also among the rare artists who received music awards in Hong Kong across every decade from the 1980s to the 2010s. \n",
    "\n",
    "For established singers like Hacken, with a vast pool of possible songs to perform, crafting a setlist often means striking a balance between hit songs and lesser-known sidetracks. This characteristic makes his concerts especially interesting for setlist analysis.\n",
    "\n",
    "\n",
    "\n",
    "### 1.3 Why These Three Concerts?\n",
    "\n",
    "In May 2023, Hacken Lee collaborated once again with the Hong Kong Philharmonic Orchestra for a concert series at the Hong Kong Coliseum. Following that, he brought the concert on tour to mainland China in 2024 with the Guangzhou Symphony Orchestra. Earlier this year (2025), he teamed up with the Macao Orchestra for the third time to present the highly acclaimed concert of the same theme in Macau.\n",
    "\n",
    "Although the concert title varied slightly at each location—**Hacken Lee x HK Phil 2023** (弦續 李克勤·港樂演唱會) in Hong Kong, **弦续 李克勤巡回演唱会** in mainland China, and **Hacken Lee Symphonic Live in Londoner with Macao Orchestra** (李克勤·我們的交響樂) in Macau—the central themes remained consistent: *continuation* and *collaboration* \n",
    "\n",
    "- *Continuation* as  by the title (also the theme song) 「弦續」 (a homophone of 「延續」 in Cantonese), symbolizing the continuation of music\n",
    "-  *Collaboration* is embodied in the fusion with live orchestras\n",
    "\n",
    "The three setlists chosen are from:\n",
    "- **2023/05/20 @ Hong Kong**  (data sourced from *HackenZone*@FB)\n",
    "- **2024/11/30 @ Guangzhou**  (firsthand experience)\n",
    "- **2025/02/09 @ Macau**         (also firsthand)\n",
    "\n",
    "These represent the finale concerts for the Hong Kong leg, the mainland China tour, and the Macau shows respectively. *(Although the Macau concert wasn't actually the final one—as Hacken will be returned to perform there later this year—I chose it under that assumption while working on this project.)*\n",
    "\n",
    "The encore section of a live concert is especially critical in leaving a lasting impression. The finale concert usually has the most electrifying atmosphere, and performers often sing more songs during the encore. For example, Hacken performed **14 encore songs** at the finale of his *30th Anniversary Concert* in 2017.\n",
    "\n",
    "Another reason for choosing these three concerts is that Cantonese is the dominant spoken language in all three cities. As Hacken has released albums in both Cantonese and Mandarin, he often adapts his setlists based on the audience’s language. In non-Cantonese-speaking areas, some tracks are swapped out. The consistency in language across these three locations allows for a more cohesive and meaningful comparison of setlist design.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieving information from Spotify\n",
    "### 2.1 Setup & Authorization\n",
    "There is a Python library for the Spotify Web API called [Spotipy](https://spotipy.readthedocs.io/en/2.25.1/), which can be used for retrieving music data provided by the Spotify platform. For <b>authorization</b>, I followed the step on <em>Spotipy</em> documentation page and set environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spotipy\n",
    "import time\n",
    "import requests\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "#spo = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials())\n",
    "path = \"dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Retrieving overall album data\n",
    "The first step is to grab the whole album list for the given artist `id` using `artist_albums()`.\n",
    "\n",
    "NOTE1: The parameter `include_groups` have four valid values: `album`, `single`, `appears_on` and `compilation`. For the purpose of this project, there is no need to retrieve information `appears_on` type since it is mostly consisted of Spotify's self-made set of tracks, rather than those officially released by record companies.\n",
    "\n",
    "NOTE2: `artist_albums()` has a maximum number (**50**) of items to return. The while loop is needed if the artist has over 50 albums.\n",
    "\n",
    "`pandas` library is then used to turn the results into a dataframe object, drop unnecessary columns, and save the file locally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums = []\n",
    "hacken = spo.artist(\"https://open.spotify.com/artist/3PV11RNUoGfX9tMN2wVljB\")\n",
    "\n",
    "album = spo.artist_albums(hacken['id'], include_groups='album',limit=50)\n",
    "single = spo.artist_albums(hacken['id'], include_groups='single',limit=50)\n",
    "compilation = spo.artist_albums(hacken['id'], include_groups='compilation',limit=50)\n",
    "albums.extend(album['items'])\n",
    "albums.extend(single['items'])\n",
    "albums.extend(compilation['items'])\n",
    "\n",
    "while album['next']:\n",
    "    album = spo.next(album)\n",
    "    albums.extend(album['items'])\n",
    "while single['next']:\n",
    "    single = spo.next(single)\n",
    "    albums.extend(single['items'])\n",
    "while compilation['next']:\n",
    "    compilation = spo.next(compilation)\n",
    "    albums.extend(compilation['items'])\n",
    "\n",
    "df = pd.DataFrame(data=albums,columns=['name','id','release_date','album_type'])\n",
    "df.to_excel(path+\"Hacken_Lee_Albums_Full.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will yield a overall album dataset of **4** columns(`name`, `id`, `release_date`, `album_type`)\n",
    "![](img/ex0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_overall = pd.read_excel(path+\"Hacken_Lee_Albums_Full.xlsx\")\n",
    "ex_overall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Retrieving track data for each album\n",
    "For each album, `album_tracks()` is used to get every track information inside that album. Only the `id` and `name` of each track data are necessary for the next step, once again `pandas` is used.\n",
    "\n",
    "**Key Notes:**\n",
    "1. `time.sleep()` is extremely needed in this step, otherwise the process would be cutoff easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(albums['id'])):\n",
    "    print(albums['name'][i],\" started\")\n",
    "   \n",
    "    results = spo.album_tracks(albums['id'][i])\n",
    "    tracks = results['items']\n",
    "    while results['next']:\n",
    "        results = spo.next(results)\n",
    "        tracks.extend(results['items'])\n",
    "        \n",
    "    tracks_df = pd.DataFrame(data=tracks,columns=['name','id'])\n",
    "    print(albums['name'][i],\" dataframe generated\")\n",
    "    tracks_df[\"album_id\"] = albums['id'][i]\n",
    "    tracks_df.to_excel(path+str(albums['name'][i])+\".xlsx\",index=False)\n",
    "    print(str(albums['name'][i]),\" finished\")\n",
    "    time.sleep(30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, a separate dataset is created for each album, contianing **3** columns:\n",
    "- `name` (track title)\n",
    "- `id` (track unique identifier)\n",
    "- `album_id` (parent album id)\n",
    "\n",
    "![](img/ex1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_album = pd.read_excel(path+\"李克勤慶祝成立30週年演唱會.xlsx\")\n",
    "ex_album.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Retrieving audio features for each track\n",
    "Here comes the main part of data extraction. One of the most valuable asset of Spotify's database is the audio features of each track. The function `audio_features()` supports a list of `id` as parameter, which simplifies the process -- instead of retrieving audio features of a single track every time, passing as a list reduces the number of calling `audio_features()` and avoiding possible timeout. \n",
    "\n",
    "`Pandas` is once again used to drop unnecessary columns and save the file.\n",
    "\n",
    "**Key Notes:**\n",
    "1. The parameter for `time.sleep()` needs to be taken carefully in this step.\n",
    "\n",
    "2. The information provided by `audio_features()` doesn't include the name of the album and the name of track, to add these:\n",
    "    - `features_df['album_name'] = albums['name'][i]` *to copy current album name from the overall album dataset* \n",
    "    - `features_df.loc[:,'track_name'] = album['name']` *to copy all track name from the current album dataset* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(albums['id'])):\n",
    " \n",
    "    if (i>20 and i%20==0):\n",
    "        time.sleep(5)\n",
    "    print(albums['name'][i]+\" started\")\n",
    "   \n",
    "    album = pd.read_excel(path+albums['name'][i]+'.xlsx') \n",
    " \n",
    "    track_ids = []\n",
    "    for j in range(len(album['id'])):\n",
    "        track_ids.append(album['id'][j])\n",
    "    time.sleep(1)\n",
    "    print(\"Track ID concatenated\")\n",
    "    results = spo.audio_features(track_ids)\n",
    "    \n",
    "    features_df = pd.DataFrame(data=results,columns=results[0].keys())\n",
    "    print(\"DataFrame Generated\")\n",
    "    time.sleep(1)\n",
    "    features_df = features_df.drop(columns=['type','uri','track_href','analysis_url'])\n",
    " \n",
    "    features_df['album_name'] = albums['name'][i]\n",
    "    features_df.loc[:,'track_name'] = album['name']\n",
    "    features_df.to_excel(path+albums['name'][i]+'_features.xlsx',index=False)\n",
    "    \n",
    "    print(albums['name'][i]+\" finished\")\n",
    "    print('time to sleep')\n",
    "    time.sleep(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the last step, this will generate a  dataframe that have **14** columns for every album. Below is an example:\n",
    "![](img/ex2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_album_feature = pd.read_excel(path+\"李克勤慶祝成立30週年演唱會_features.xlsx\")\n",
    "ex_album_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Concatenating the feature datasets as one dataset\n",
    "For the purpose of searching and extracting one specific track information, concatenating the feature datasets into one overall dataset would be extremely useful in terms of saving time. \n",
    "\n",
    "**Key Notes:**\n",
    "1. For readability's sake, this line `album = album.iloc[:, [15, 11, 14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13]] ` is used to reorder the columns, so that `track_name`, `id`, `album_name` would be the first three columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_features = []\n",
    "total_albums_features = []  \n",
    "for i in range(len(albums['id'])):\n",
    "    album = pd.read_excel(path + albums['name'][i] + '_features.xlsx')\n",
    "    album = album.iloc[:, [15, 11, 14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13]] \n",
    "    albums.append(album)\n",
    "\n",
    "album_features_total = pd.concat(total_albums_features)\n",
    "album_features_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Retrieving the Play Count Data using Public API\n",
    "**Disclaimer**: This project is to be used for **education purpose** only.\n",
    "\n",
    "Let's back to this project's first research question: <em>How are hit songs and lesser-known sidetracks balanced across the setlists?</em>. To answer this, we need to define what are hit songs and what are sidetracks. Every fan may give a different opinion about this. Thus, an objective measure is needed. \n",
    "\n",
    "#### 2.6.1 Popularity Data from Spotify and Why Not Applicable\n",
    "Spotify's API provides the popularity data of a track object, which <em>\"is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are\"</em>. In some cases it may reflect how popular the track is, but its nature in which duplicate tracks are rated independently determined that it's not suitable for this project.\n",
    "\n",
    "Why? It's not unusual that record companies release compilation albums every few years and listeners may tend to listen one compilation album rather than search for the particular album when one song is released in. Therefore, it's not really a proper choice as one track's popularity data would be dispersed into different version.\n",
    "\n",
    "#### 2.6.2 Play Count Data Using Public API\n",
    "Spotify also have the play counts for each track, although not accessible using its official API. After doing some research, I found out that for the same track, Spotify adds up every version's play counts and treat it the same for every version -- which is exactly what I need. \n",
    "\n",
    "A sincere thank to the author of [this github project](https://github.com/entriphy/sp-playcount-librespot), who provides a public api to retrieve the play count of all tracks in a Spotify album.\n",
    "\n",
    "`requests` library is used to handle the response returned, `pandas` is then used to merge the results to previous features dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hacken_albums = pd.read_excel(path+\"Hacken_Lee_Albums_Full.xlsx\")\n",
    "\n",
    "base_url = \"https://api.t4ils.dev/albumPlayCount\"\n",
    "for i in range(len(hacken_albums['id'])):\n",
    "    if (i>61 and i%10==0):\n",
    "        print(\"it's time to sleep\")\n",
    "        time.sleep(5)\n",
    "    album_id = hacken_albums['id'][i]  \n",
    "\n",
    "  \n",
    "    url = f\"{base_url}?albumid={album_id}\"\n",
    "    response = requests.get(url)\n",
    "    print(hacken_albums['name'][i],\" started\")\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "    \n",
    "        if data.get('success'):\n",
    "            play_count_data = []\n",
    "            album_data = data.get('data',{})\n",
    "            for disc in album_data.get('discs', []):\n",
    "                for track in disc.get('tracks', []):\n",
    "                    track_id = track.get('uri').split(\":\")[-1] \n",
    "                    play_count = track.get('playcount')\n",
    "                    play_count_data.append({'id': track_id, 'play_count': play_count})\n",
    "            \n",
    "         \n",
    "            play_count_df = pd.DataFrame(play_count_data)\n",
    "            print(play_count_df.head())\n",
    "          \n",
    "            existing_data = pd.read_excel(path+hacken_albums['name'][i]+\"_features.xlsx\")\n",
    "            updated_data = existing_data.merge(play_count_df, on='id', how='left')\n",
    "        \n",
    "            updated_data.to_excel(path+hacken_albums['name'][i]+\"_features.xlsx\", index=False)\n",
    "            print(\"Play count data successfully merged into the Excel sheet.\")\n",
    "        \n",
    "        else:\n",
    "            print(\"API response indicates failure.\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data. HTTP Status Code: {response.status_code}\")\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.3 Update the Overall Feature Dataset\n",
    "After grabbing the play count data for each album, the overall dataset needs to be updated as follows. \n",
    "\n",
    "**Key Notes:**\n",
    "1. The order of albums in the overall feature dataset follows the same order as in the overall album dataset, which simplifies the process -- just a nested for loop will do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playcount_list = []\n",
    "\n",
    "for i in range(len(hacken_albums['id'])):\n",
    "    album_name = hacken_albums.loc[i, \"name\"]\n",
    "    print(f\"{album_name} started\")\n",
    "\n",
    "    album = pd.read_excel(path + album_name + \"_features.xlsx\")\n",
    "  \n",
    "    for j in range(len(album['id'])):\n",
    "        playcount_list.append(album.loc[j, 'play_count'])\n",
    "\n",
    "hacken_features = pd.read_excel(path + \"Hacken_Lee_Albums_Features_Full.xlsx\")\n",
    "hacken_features['play_count'] = playcount_list\n",
    "\n",
    "hacken_features.to_excel(path+\"Hacken_Lee_Albums_Features_Updated.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now, everything needed from Spotify has been retrieved and saved in several datasets. Let's proceed to extract setlist data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extracting Setlist Data\n",
    "\n",
    "**Key Notes:**\n",
    "\n",
    "In this part, only two overall datasets are needed:\n",
    "1. `hacken_albums`: the overall album list which contains every album's `name`, `id`, `release_date` and `album_type`\n",
    "2. `hacken_features`: the overall feature list which contains every track's audio features data, `album_name`, `track_name`, and `play_count`\n",
    "\n",
    "### 3.1 Searching for Specific Track Data\n",
    "The first step is obviously to make a list of names of the tracks that Hacken performed in those three concerts respectively. Using `pandas`'s function `.isin()` can do a quick and shallow filter based on the tracks' name. But a problem emerges as follows: how to deal with duplicates? Pick my favourite song as an example, here is the result for `hacken_features[hacken_features['track_name'].str.contains(\"好戲之人\")][[\"track_name\",\"album_name\",\"play_count\"]]`.\n",
    "![](img/ex3.png)\n",
    "\n",
    "It's clearly that one single track would have several versions (studio album, compilation, or live). In order to answer the second research question: *Which albums are most favoured?*, only one version is needed, that is, the first album that the track is released in. \n",
    "\n",
    "**Key Notes**:\n",
    "1. Since the feature dataset doesn't contain information of release date, a merge operation is required. The logic of this merge step is to add the `release_date` cell value based on the match for album name. As the representative column of album name have different names (`album_name` in feature dataset and `name` in album dataset), an *inner join* is the only method that works.\n",
    "\n",
    "2. The type of `release_date` is string, it needs to be reformated to datetime object first. \n",
    "\n",
    "Below is an example code for extracting the data for setlist in Macau concert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list_macau = [\n",
    "    \"希望\", \"一個都不能少\", \"破曉時份\", \"只想你會意\", \"舊歡如夢\", \n",
    "    \"護花使者\", \"藍月亮\", \"C3PO\", \"回首\", \"一生不變\", \n",
    "    \"Victory\", \"天水、圍城\", \"刻不容緩\", \"最愛\", \"沒有你贏了世界又如何\",\"告別校園時\",\n",
    "    \"再見演奏廳\",\"深深深\",\"紅日\",\"夏日之神話\",\"月半小夜曲\",\"我不會唱歌\",\"高妹\",\"合久必分\",\"飛花\"\n",
    "]\n",
    "\n",
    "\n",
    "filtered_df = hacken_features[hacken_features['track_name'].isin(track_list_macau)]\n",
    "\n",
    "\n",
    "merged_filtered_df = pd.merge(\n",
    "    filtered_df, \n",
    "    hacken_albums[['name', 'release_date']], \n",
    "    left_on='album_name', \n",
    "    right_on='name', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "\n",
    "merged_filtered_df['release_date'] = pd.to_datetime(merged_filtered_df['release_date'])\n",
    "\n",
    "plot_data = merged_filtered_df.loc[merged_filtered_df.groupby('track_name')['release_date'].idxmin()]\n",
    "\n",
    "plot_data['release_year'] = plot_data['release_date'].dt.year\n",
    "\n",
    "plot_data = plot_data.drop(columns=['release_date',\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Manual Adjustment\n",
    "#### 3.2.1 Correction for Tracks' Release Year\n",
    "\n",
    "Due to copyright issues, some of Hacken's albums are not available on Spotify. (Particularly those released by Impact Entertainment.) Thus, in the last step of selecting the first release album, what is selected is the earliest album that Spotify has data for. To pursue authenticity, manual correction for albums is necessary in this step.\n",
    "\n",
    "#### 3.2.2 Adding Record Company Information\n",
    "\n",
    "For visualization, it would be more intuitive if every track/album data point is labelled with a color corresponding to the record company.\n",
    "\n",
    "As said in the introduction, Hacken's career spans from the 1980s to 2020s (and is still ongoing), *unavoidably* (I use this word in considering the fact of record industry development in Hong Kong from the 1980s to now) he has collaborated with 5 different record companies:\n",
    "- PolyGram (*1986-1993*)\n",
    "- Star (*1993-1996*)\n",
    "- Music Impact Entertainment (*1996-1998*)\n",
    "- Universal Music Hong Kong (*1999-2016*)\n",
    "- Emperor Entertainment Group (*2016-now*)\n",
    "\n",
    "Although Spotify contains a copyright statement for an album, for some albums the information is missing. In this case, it would be more time-saving to enter the record company value manually as I have prior knowledge (with the help of those physical CDs I owned).\n",
    "\n",
    "#### 3.2.3 Classifying Tracks Based on Position\n",
    "Normally a setlist of a concert is consisted of fixed songs and encore songs. Classifying the tracks into `main` and `encore` types allows me to have a better examine at the first research question.\n",
    "\n",
    "**Key Notes:**\n",
    "1. Usually the encore part lies the last of a concert, but here the setlist of the Hong Kong one makes the exception -- as Hacken performed different songs every night during the orchestra's intermission time. Hence I feel more appropriate to put those four songs into the category of '*encore songs*'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>id</th>\n",
       "      <th>album_name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>play_count</th>\n",
       "      <th>release_year</th>\n",
       "      <th>record_company</th>\n",
       "      <th>rundown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C3PO</td>\n",
       "      <td>18BLNafwAjUQhmWXx3BY7E</td>\n",
       "      <td>30克</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.470</td>\n",
       "      <td>7</td>\n",
       "      <td>-8.663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.373</td>\n",
       "      <td>70.122</td>\n",
       "      <td>232253</td>\n",
       "      <td>4</td>\n",
       "      <td>2303153</td>\n",
       "      <td>2017</td>\n",
       "      <td>英皇</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>一個都不能少</td>\n",
       "      <td>6vicNEMPZ2xyFMJwYGBRPz</td>\n",
       "      <td>30克</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.361</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.431</td>\n",
       "      <td>110.324</td>\n",
       "      <td>206360</td>\n",
       "      <td>4</td>\n",
       "      <td>890930</td>\n",
       "      <td>2017</td>\n",
       "      <td>英皇</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一生不變</td>\n",
       "      <td>0I1bQXS2ktUPw1ANBw6vOX</td>\n",
       "      <td>Purple Dream</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.268</td>\n",
       "      <td>8</td>\n",
       "      <td>-18.405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.316</td>\n",
       "      <td>66.502</td>\n",
       "      <td>262373</td>\n",
       "      <td>4</td>\n",
       "      <td>5515647</td>\n",
       "      <td>1989</td>\n",
       "      <td>寶麗金</td>\n",
       "      <td>encore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>再見演奏廳</td>\n",
       "      <td>0Cv07c5pmSqhX1AV5LraTv</td>\n",
       "      <td>Hacken Lee No. 1 Hits</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.452</td>\n",
       "      <td>6</td>\n",
       "      <td>-9.802</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.190</td>\n",
       "      <td>81.871</td>\n",
       "      <td>215440</td>\n",
       "      <td>4</td>\n",
       "      <td>138894</td>\n",
       "      <td>2007</td>\n",
       "      <td>環球</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>合久必婚</td>\n",
       "      <td>0YXOc4ngvaxhB0IJRFNvTh</td>\n",
       "      <td>Custom Made</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.618</td>\n",
       "      <td>6</td>\n",
       "      <td>-7.543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.439</td>\n",
       "      <td>111.477</td>\n",
       "      <td>192627</td>\n",
       "      <td>4</td>\n",
       "      <td>11101715</td>\n",
       "      <td>2003</td>\n",
       "      <td>環球</td>\n",
       "      <td>encore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_name                      id             album_name  danceability  \\\n",
       "0       C3PO  18BLNafwAjUQhmWXx3BY7E                    30克         0.538   \n",
       "1     一個都不能少  6vicNEMPZ2xyFMJwYGBRPz                    30克         0.528   \n",
       "2       一生不變  0I1bQXS2ktUPw1ANBw6vOX           Purple Dream         0.539   \n",
       "3      再見演奏廳  0Cv07c5pmSqhX1AV5LraTv  Hacken Lee No. 1 Hits         0.468   \n",
       "4       合久必婚  0YXOc4ngvaxhB0IJRFNvTh            Custom Made         0.629   \n",
       "\n",
       "   energy  key  loudness  mode  speechiness  acousticness  instrumentalness  \\\n",
       "0   0.470    7    -8.663     1       0.0418         0.734          0.000000   \n",
       "1   0.361    1    -9.536     1       0.0328         0.825          0.000042   \n",
       "2   0.268    8   -18.405     1       0.0368         0.485          0.000046   \n",
       "3   0.452    6    -9.802     1       0.0402         0.790          0.000133   \n",
       "4   0.618    6    -7.543     1       0.0341         0.594          0.000000   \n",
       "\n",
       "   liveness  valence    tempo  duration_ms  time_signature  play_count  \\\n",
       "0    0.0963    0.373   70.122       232253               4     2303153   \n",
       "1    0.1190    0.431  110.324       206360               4      890930   \n",
       "2    0.0909    0.316   66.502       262373               4     5515647   \n",
       "3    0.0710    0.190   81.871       215440               4      138894   \n",
       "4    0.1280    0.439  111.477       192627               4    11101715   \n",
       "\n",
       "   release_year record_company rundown  \n",
       "0          2017             英皇    main  \n",
       "1          2017             英皇    main  \n",
       "2          1989            寶麗金  encore  \n",
       "3          2007             環球    main  \n",
       "4          2003             環球  encore  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hk_setlist = pd.read_excel(path+\"23HongKong.xlsx\")\n",
    "hk_setlist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization\n",
    "### 4.1 Quadrant Chart\n",
    "Similar to a scatter plot, a quadrant chart is used to identify patterns or trends in data using an XY axis. However, what distinguishes a quadrant chart is that the origin of the two axes lies at the middle point, typically the center of the field, thus forming four distinct areas. The key difference between these two types of charts is the direction of values increases -- in quadrant charts, values increase in positive and negative directions as they expand from the center. \n",
    "\n",
    "To address the first question: *How are hit songs and lesser-known sidetracks balanced across the setlists?* The play count data serves as one axis, as it was established in **Section 2.6** as the objective classification metric. A straightforward approach is to use the average play count as a threshold: tracks exceeding this value are classified as \"hit songs\", while other are considered sidetracks. \n",
    "\n",
    "For the other axis, the track's release year is selected. The year range is deliberately fixed from *1985* to *2025* (rather than using the actual earliest and latest years) for two reasons:\n",
    "1. A fixed range facilitates cross-comparison among the three setlists\n",
    "2. The middle point, or the *origin*, corresponds to 2005 -- the year Hacken won *Most popular male signer* for the third time\n",
    "\n",
    "\n",
    "Thus, this step aims to create quadrant charts with:\n",
    "- X-axis: Release year (from *1985* to *2025*)\n",
    "- Y-axis: Log-transformed play count (from *8* to *18*)\n",
    "\n",
    "**Key Notes:**\n",
    "1. Log transformation is applied to play counts due to their extreme range (e.g., a ~1 million difference between the top two tracks). Without this, most tracks would cluster near the bottom.\n",
    "2. Color-coding track spots by their record company (via the `record_company` column) may reveal *label-specific* patterns, also color-coding track text by the type (via the `rundown` column) mentioned in **Section 3.2.3** may reveal *position-specific* patterns.\n",
    "\n",
    "Below is an example code for creating the quadrant chart for Hong Kong setlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "\n",
    "matplotlib.rcParams['font.family'] = ['Heiti TC']\n",
    "\n",
    "no_duplicate_df = pd.read_excel(path+\"23HongKong.xlsx\")\n",
    "\n",
    "\n",
    "no_duplicate_df['log_play_count'] = np.log1p(no_duplicate_df['play_count'])\n",
    "\n",
    "color_id = {\n",
    "     '寶麗金': '#84594d',  \n",
    "    '星光': '#a9d8e4',  \n",
    "    '藝能': '#c6c6c6',  \n",
    "    '環球': '#a7dc91',  \n",
    "    '英皇': '#3975b1'   \n",
    "}\n",
    "tran_Name = {\n",
    "    '寶麗金': 'PolyGram', \n",
    "    '星光': 'Star',  \n",
    "    '藝能': 'Music Impact Entertainment',\n",
    "    '環球': 'Universal', \n",
    "    '英皇': 'EEG'  \n",
    "}\n",
    "\n",
    "\n",
    "no_duplicate_df['RecordCompanyEN'] = no_duplicate_df['record_company'].map(tran_Name)\n",
    "no_duplicate_df['color'] = no_duplicate_df['record_company'].map(color_id)\n",
    "rundown_color_map = {'main': 'black', 'encore': '#c9a1ed'}\n",
    "no_duplicate_df['text_color'] = no_duplicate_df['rundown'].map(rundown_color_map)\n",
    "\n",
    "x = no_duplicate_df['release_year']\n",
    "y = no_duplicate_df['log_play_count']\n",
    "\n",
    "\n",
    "x_min, x_max = 1985, 2025\n",
    "y_min, y_max = 8,18\n",
    "x_mid = x_min + (x_max - x_min) / 2\n",
    "y_mid = y_min + (y_max - y_min) / 2\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for company, group in no_duplicate_df.groupby('RecordCompanyEN'):\n",
    "    ax.scatter(\n",
    "        group['release_year'],\n",
    "        group['log_play_count'],\n",
    "        label=company,\n",
    "        color=group['color'].iloc[0],\n",
    "        edgecolor='black',\n",
    "        s=100\n",
    "        \n",
    "    )\n",
    "\n",
    "texts = []\n",
    "for i, row in no_duplicate_df.iterrows():\n",
    "    texts.append(\n",
    "        ax.text(\n",
    "            row['release_year']+0.3,\n",
    "            row['log_play_count']-0.1,\n",
    "            row['track_name'],\n",
    "            fontsize=12,\n",
    "            ha='left',\n",
    "            color=row['text_color']\n",
    "        )\n",
    "    )\n",
    "adjust_text(texts,arrowprops=dict(arrowstyle='->', color='red'))\n",
    "\n",
    "\n",
    "ax.axvline(x=x_mid, color='#c2d6f3', linestyle='--', linewidth=1)\n",
    "ax.axhline(y=y_mid, color='#c2d6f3', linestyle='--', linewidth=1)\n",
    "ax.set_xlim(1985,2025)\n",
    "ax.set_ylim(8,18)\n",
    "\n",
    "ax.set_title('Hacken Lee X HKPhil Concert 2023 Rundown', fontsize=16)\n",
    "ax.set_xlabel('Release Year', fontsize=12)\n",
    "ax.set_ylabel('Log-Scaled Popularity', fontsize=12)\n",
    "ax.legend(title=\"Record Company\", loc='upper right')\n",
    "plt.text(0.85,\n",
    "         0.77,\n",
    "         \"a watermark by wend1k3\",\n",
    "         transform=plt.gca().transAxes,\n",
    "            ha='center',  \n",
    "            va='center',  \n",
    "            alpha=1,\n",
    "                fontdict=dict(\n",
    "                    fontsize=11,\n",
    "                    color='#ecacbd',\n",
    "                    family=\n",
    "                    \"Heiti TC\",  \n",
    "                    weight=\n",
    "                    'normal', \n",
    "                )  )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "Here are the three quadrant charts corresponding to three setlist.\n",
    "![](img/23HKquadrant.png)\n",
    "![](img/24GZquadrant.png)\n",
    "![](img/25OMquadrant.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Bar Plot\n",
    "In the last section, the first question is properly addressed. Now, the second one: *Which albums are most favoured?* To answer this, comparisons of amounts of tracks selected per album is a necessity. The right type of visualization to it is a bar plot. The reason for not choosing pie chart is that it is easier to compare bar heights than pie slice sizes.\n",
    "\n",
    "Manual correction is again needed in this step as albums has become the main focus in this part. Although in **Section 3.2** correction for release year has been done, there might still are mis-matching between tracks and the first released albums. For this project's purpose, the notion of album is to be considered as the *full*, *studio* albums. It is quite common that record companies may release a single or EP before the full album, which come across a few times when dealing with the data, but it is meaningless to analyze.\n",
    "\n",
    "Therefore, this step aims to create bar plots with:\n",
    "- X-axis: release year (range based on actual *earliest* and *latest* year)\n",
    "- Y-axis: number of tracks selected\n",
    "\n",
    "**Key Notes:**\n",
    "1. For this visualization, only 4 columns are needed: `track_name`, `album_name`, `release_year`, `record_company`. Filtering these columns first would make the manual correction step easier.\n",
    "2. Sorting the value of `release_year` is for consideration of x-axis, following the same chronological order as the quadrant chart provides better view by maintaining the consistency.\n",
    "\n",
    "Below is an example code for wrangling data of Guangzhou setlist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzrd = pd.read_excel(path+\"24Guangzhou.xlsx\")\n",
    "gzrd = gzrd[[\"track_name\",\"album_name\",\"release_year\",\"record_company\"]]\n",
    "gzrd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_counts = gzrd.groupby([\"album_name\", \"release_year\",\"record_company\"]).size().reset_index(name=\"track_count\")\n",
    "album_counts = album_counts.sort_values(by=\"release_year\")\n",
    "album_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 (Optional) Adding Album Artwork Image to Bar Plot\n",
    " \n",
    "The human brain processes images around **60,000** times faster than text. Incorporating relevant images into visualization makes the information more memorable by grabbing the attention of the audience.  \n",
    "\n",
    "An album cover has always been maintained as a vital part of the musical experience -- whether back in physical vinyl/CD time where music enthusiasts may get a sense of a person's music taste by glancing at the covers of vinyl/CD collection or now, as in the digital music streaming era, becomes \"the reason why someone would decide to listen to the music\".  \n",
    "\n",
    "Therefore, by adding album cover images to the bar plot would make the data more relatable and engaging for the audience. For myself, I would tend to link up the track information more closely with the album cover rather than the mere album name -- that's say, if you ask me which album is a particular song released in, my mind would definitely pop out the cover art first, followed by the album name later.\n",
    "\n",
    "**Key Notes:**\n",
    "1. Although Spotify API do provide the method for accessing to an album's artwork, the maximum resolution is only up to 300x300 pixels. There exists a way to grab the high resolution images from Apple Music (and the majority of the cover arts in the below visualizations are acquired in this way, a few are through physical scanning as not provided on neither of these two platforms). This step is done manually and not considered as the \"technical\" part.\n",
    "2. There is an odd file type requirement for adding additional images to the bar plot generated by `matplotlib`, that is, the images have to be in `.png` format. Otherwise they won't show up in the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = ['Microsoft YaHei']\n",
    "\n",
    "color_id = {\n",
    "    '寶麗金': '#84594d',  \n",
    "    '星光': '#a9d8e4',  \n",
    "    '藝能': '#c6c6c6',  \n",
    "    '環球': '#a7dc91',  \n",
    "    '英皇': '#3975b1'   \n",
    "}\n",
    "tran_Name = {\n",
    "    '寶麗金': 'PolyGram', \n",
    "    '星光': 'Star',  \n",
    "    '藝能': 'Music Impact Entertainment',\n",
    "    '環球': 'Universal', \n",
    "    '英皇': 'EEG'  \n",
    "}\n",
    "\n",
    "\n",
    "album_counts['RecordCompanyEN'] = album_counts['record_company'].map(tran_Name)\n",
    "\n",
    "album_counts['color'] = album_counts['record_company'].map(color_id).fillna('gray')  \n",
    "\n",
    "\n",
    "album_counts[\"x_label\"] = album_counts[\"album_name\"] + \"\\n'\" + album_counts[\"release_year\"].astype(str).str[-2:]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24, 12))\n",
    "bars = ax.bar(album_counts[\"x_label\"], album_counts[\"track_count\"], color=album_counts[\"color\"], edgecolor=\"black\")\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Album Name with Release Year\")\n",
    "ax.set_ylabel(\"Number of Tracks Selected\")\n",
    "ax.set_title(\"Number of Tracks in Each Album Sorted by Release Year For Hacken Lee X GSO 2024 Rundown\")\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))  \n",
    "\n",
    "\n",
    "image_folder = \"artwork//\"  \n",
    "\n",
    "\n",
    "ax.set_ylim(0, max(album_counts[\"track_count\"]) + 0.25)  \n",
    "ax.set_xlim(-0.5, len(album_counts[\"album_name\"]) - 0.5)  \n",
    "\n",
    "\n",
    "for bar, album_name, track_count in zip(bars, album_counts[\"album_name\"], album_counts[\"track_count\"]):\n",
    "    image_path = os.path.join(image_folder, f\"{album_name}.png\")  \n",
    "\n",
    "    \n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,  \n",
    "        bar.get_height() ,  \n",
    "        f\"{track_count}\",  \n",
    "        ha='center', va='bottom',  \n",
    "         fontsize=14, color='black'\n",
    "    )\n",
    "\n",
    "    if os.path.exists(image_path):  \n",
    "        img = mpimg.imread(image_path)  \n",
    "\n",
    "      \n",
    "        img_height, img_width = img.shape[:2]\n",
    "        aspect_ratio = img_height / img_width\n",
    "\n",
    "       \n",
    "        x0 = bar.get_x()  \n",
    "        x1 = bar.get_x() + bar.get_width()  \n",
    "        img_width_scaled = x1 - x0  \n",
    "        img_height_scaled = img_width_scaled * aspect_ratio  \n",
    "\n",
    "        y1 = img_height_scaled * 0.5  \n",
    "        y0 = 0  \n",
    "\n",
    "        \n",
    "        ax.imshow(img, extent=[x0, x1, y0, y1], aspect='auto', zorder=2)\n",
    "\n",
    "\n",
    "legend_patches = [Patch(color=color, label=tran_Name[company]) for company, color in color_id.items()]\n",
    "\n",
    "ax.legend(handles=legend_patches,  loc=\"upper center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/23HKbar.png)\n",
    "![](img/24GZbar.png)\n",
    "![](img/25OMbar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion\n",
    "\n",
    "### 5.3 Further Question\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
